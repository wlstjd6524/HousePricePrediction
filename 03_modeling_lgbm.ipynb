{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "919c4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "fe = fm.FontEntry(\n",
    "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # ttf íŒŒì¼ì´ ì €ì¥ë˜ì–´ ìˆëŠ” ê²½ë¡œ\n",
    "    name='NanumBarunGothic')                        # ì´ í°íŠ¸ì˜ ì›í•˜ëŠ” ì´ë¦„ ì„¤ì •\n",
    "fm.fontManager.ttflist.insert(0, fe)              # Matplotlibì— í°íŠ¸ ì¶”ê°€\n",
    "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # í°íŠ¸ ì„¤ì •\n",
    "plt.rc('font', family='NanumBarunGothic')\n",
    "import seaborn as sns\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# utils\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings;warnings.filterwarnings('ignore')\n",
    "\n",
    "# Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21642a2",
   "metadata": {},
   "source": [
    "##### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "545e99e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape: (1118822, 127)\n",
      "test_df  shape: (9272, 127)\n",
      "\n",
      "train_df ì»¬ëŸ¼ ì˜ˆì‹œ: ['ì‹œêµ°êµ¬', 'ë²ˆì§€', 'ë³¸ë²ˆ', 'ë¶€ë²ˆ', 'ì•„íŒŒíŠ¸ëª…', 'ì „ìš©ë©´ì ', 'ê³„ì•½ë…„ì›”', 'ê³„ì•½ì¼', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'ë„ë¡œëª…', 'í•´ì œì‚¬ìœ ë°œìƒì¼', 'ë“±ê¸°ì‹ ì²­ì¼ì', 'ê±°ë˜ìœ í˜•', 'ì¤‘ê°œì‚¬ì†Œì¬ì§€', 'k-ë‹¨ì§€ë¶„ë¥˜(ì•„íŒŒíŠ¸,ì£¼ìƒë³µí•©ë“±ë“±)', 'ë‹¨ì§€ì†Œê°œê¸°ì¡´clob', 'k-ì„¸ëŒ€íƒ€ì…(ë¶„ì–‘í˜•íƒœ)', 'k-ê´€ë¦¬ë°©ì‹', 'k-ë³µë„ìœ í˜•', 'k-ë‚œë°©ë°©ì‹', 'k-ì „ì²´ë™ìˆ˜', 'k-ì „ì²´ì„¸ëŒ€ìˆ˜', 'k-ê±´ì„¤ì‚¬(ì‹œê³µì‚¬)', 'k-ì‹œí–‰ì‚¬']\n",
      "\n",
      "[train_df is_test ë¶„í¬]\n",
      "is_test\n",
      "0    1118822\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[Target ê°’ ê¸°ì´ˆ í†µê³„]\n",
      "count    1.118822e+06\n",
      "mean     5.799153e+04\n",
      "std      4.642602e+04\n",
      "min      3.500000e+02\n",
      "25%      3.050000e+04\n",
      "50%      4.480000e+04\n",
      "75%      6.980000e+04\n",
      "max      1.450000e+06\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "TRAIN_FE_PATH = \"./Data/02_feature_end/train_fe.pkl\"\n",
    "TEST_FE_PATH  = \"./Data/02_feature_end/test_fe.pkl\"\n",
    "\n",
    "train_df = pd.read_pickle(TRAIN_FE_PATH)\n",
    "test_df  = pd.read_pickle(TEST_FE_PATH)\n",
    "\n",
    "print(\"train_df shape:\", train_df.shape)\n",
    "print(\"test_df  shape:\", test_df.shape)\n",
    "\n",
    "print(\"\\ntrain_df ì»¬ëŸ¼ ì˜ˆì‹œ:\", list(train_df.columns)[:25])\n",
    "\n",
    "print(\"\\n[train_df is_test ë¶„í¬]\")\n",
    "print(train_df[\"is_test\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\n[Target ê°’ ê¸°ì´ˆ í†µê³„]\")\n",
    "print(train_df[\"target\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fdb9e3",
   "metadata": {},
   "source": [
    "##### Feature / Target ë¶„ë¦¬í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91eba161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_feature_cols ê°œìˆ˜: 125\n",
      "í”¼ì²˜ ê°œìˆ˜: 125\n",
      "í”¼ì²˜ ì˜ˆì‹œ 20ê°œ: ['ì‹œêµ°êµ¬', 'ë²ˆì§€', 'ë³¸ë²ˆ', 'ë¶€ë²ˆ', 'ì•„íŒŒíŠ¸ëª…', 'ì „ìš©ë©´ì ', 'ê³„ì•½ë…„ì›”', 'ê³„ì•½ì¼', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'ë„ë¡œëª…', 'í•´ì œì‚¬ìœ ë°œìƒì¼', 'ë“±ê¸°ì‹ ì²­ì¼ì', 'ê±°ë˜ìœ í˜•', 'ì¤‘ê°œì‚¬ì†Œì¬ì§€', 'k-ë‹¨ì§€ë¶„ë¥˜(ì•„íŒŒíŠ¸,ì£¼ìƒë³µí•©ë“±ë“±)', 'ë‹¨ì§€ì†Œê°œê¸°ì¡´clob', 'k-ì„¸ëŒ€íƒ€ì…(ë¶„ì–‘í˜•íƒœ)', 'k-ê´€ë¦¬ë°©ì‹', 'k-ë³µë„ìœ í˜•']\n",
      "í”¼ì²˜ 110ê°œ: ['ì‹œêµ°êµ¬', 'ë²ˆì§€', 'ë³¸ë²ˆ', 'ë¶€ë²ˆ', 'ì•„íŒŒíŠ¸ëª…', 'ì „ìš©ë©´ì ', 'ê³„ì•½ë…„ì›”', 'ê³„ì•½ì¼', 'ì¸µ', 'ê±´ì¶•ë…„ë„', 'ë„ë¡œëª…', 'í•´ì œì‚¬ìœ ë°œìƒì¼', 'ë“±ê¸°ì‹ ì²­ì¼ì', 'ê±°ë˜ìœ í˜•', 'ì¤‘ê°œì‚¬ì†Œì¬ì§€', 'k-ë‹¨ì§€ë¶„ë¥˜(ì•„íŒŒíŠ¸,ì£¼ìƒë³µí•©ë“±ë“±)', 'ë‹¨ì§€ì†Œê°œê¸°ì¡´clob', 'k-ì„¸ëŒ€íƒ€ì…(ë¶„ì–‘í˜•íƒœ)', 'k-ê´€ë¦¬ë°©ì‹', 'k-ë³µë„ìœ í˜•', 'k-ë‚œë°©ë°©ì‹', 'k-ì „ì²´ë™ìˆ˜', 'k-ì „ì²´ì„¸ëŒ€ìˆ˜', 'k-ê±´ì„¤ì‚¬(ì‹œê³µì‚¬)', 'k-ì‹œí–‰ì‚¬', 'k-ì‚¬ìš©ê²€ì‚¬ì¼-ì‚¬ìš©ìŠ¹ì¸ì¼', 'k-ì—°ë©´ì ', 'k-ì£¼ê±°ì „ìš©ë©´ì ', 'k-ê´€ë¦¬ë¹„ë¶€ê³¼ë©´ì ', 'k-ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©(60ã¡ì´í•˜)', 'k-ì „ìš©ë©´ì ë³„ì„¸ëŒ€í˜„í™©(60ã¡~85ã¡ì´í•˜)', 'k-85ã¡~135ã¡ì´í•˜', 'k-135ã¡ì´ˆê³¼', 'ê²½ë¹„ë¹„ê´€ë¦¬í˜•íƒœ', 'ì„¸ëŒ€ì „ê¸°ê³„ì•½ë°©ë²•', 'ì²­ì†Œë¹„ê´€ë¦¬í˜•íƒœ', 'ê±´ì¶•ë©´ì ', 'ì£¼ì°¨ëŒ€ìˆ˜', 'ê¸°íƒ€/ì˜ë¬´/ì„ëŒ€/ì„ì˜=1/2/3/4', 'ë‹¨ì§€ìŠ¹ì¸ì¼', 'ì‚¬ìš©í—ˆê°€ì—¬ë¶€', 'ê´€ë¦¬ë¹„ ì—…ë¡œë“œ', 'ì¢Œí‘œX', 'ì¢Œí‘œY', 'ë‹¨ì§€ì‹ ì²­ì¼', 'ë³¸ë²ˆ_missing', 'ë¶€ë²ˆ_missing', 'ì•„íŒŒíŠ¸ëª…_missing', 'ë²ˆì§€_missing', 'has_cancelled', 'ì‹œ', 'êµ¬', 'ë™', 'êµ¬_í‰ê· ê°€ê²©', 'êµ¬_ì¤‘ìœ„ê°€ê²©', 'êµ¬_ê±°ë˜ëŸ‰', 'ë™_í‰ê· ê°€ê²©', 'ë™_ê±°ë˜ëŸ‰', 'ê°•ë‚¨ì—¬ë¶€', 'CBD_ì—¬ë¶€', 'GBD_ì—¬ë¶€', 'YBD_ì—¬ë¶€', 'subway_min_dist_km', 'subway_is_500m', 'subway_cnt_500m', 'subway_cnt_1km', 'bus_min_dist_km', 'bus_cnt_300m', 'bus_cnt_500m', 'bus_is_300m', 'bus_is_500m', 'elem_min_dist_km', 'mid_min_dist_km', 'high_min_dist_km', 'school_min_dist_km', 'elem_school_cnt', 'mid_school_cnt', 'high_school_cnt', 'building_age', 'building_age_bucket', 'is_new', 'is_old_redev', 'year_group', 'year_sq', 'year_sqrt', 'floor_bucket', 'floor_abs', 'is_low_floor', 'is_mid_floor', 'is_high_floor', 'max_floor_in_complex', 'is_top_floor', 'complex_scale', 'avg_age_by_dong', 'avg_floor_by_dong', 'ratio_new_buildings', 'log_area', 'area_pyeong', 'area_bucket', 'dong_avg_pyp', 'contract_year', 'contract_month', 'contract_quarter', 'season', 'yearly_price_growth', 'same_apt_area_total_trades', 'same_apt_area_past_trades', 'is_brand_apt', 'has_redev_keyword', 'has_scale_keyword']\n",
      "\n",
      "X shape: (1118822, 125)\n",
      "y shape: (1118822,)\n"
     ]
    }
   ],
   "source": [
    "# Feature / Target ë¶„ë¦¬í•˜ê¸° ì›ë³¸\n",
    "TARGET_COL = \"target\"\n",
    "\n",
    "# ëª¨ë¸ì— ë„£ì§€ ì•Šì„ ì»¬ëŸ¼ë“¤\n",
    "NON_FEATURE_COLS = [\n",
    "    TARGET_COL,\n",
    "    \"is_test\",\n",
    "    # ë§Œì•½ id, row_id ê°™ì€ ì»¬ëŸ¼ ìˆìœ¼ë©´ ì—¬ê¸° ì¶”ê°€\n",
    "]\n",
    "\n",
    "# í”¼ì²˜ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸\n",
    "orig_feature_cols = [c for c in train_df.columns if c not in NON_FEATURE_COLS]\n",
    "\n",
    "'''\n",
    "# ì‚­ì œ í›„ë³´\n",
    "interest_features = [\"base_rate\", \"rate_mom\", \"rate_yoy\", \"rate_bucket\"]\n",
    "\n",
    "for f in interest_features:\n",
    "    if f in train_df.columns and f not in orig_feature_cols:\n",
    "        orig_feature_cols.append(f)\n",
    "'''\n",
    "\n",
    "print(\"orig_feature_cols ê°œìˆ˜:\", len(orig_feature_cols))\n",
    "\n",
    "print(\"í”¼ì²˜ ê°œìˆ˜:\", len(orig_feature_cols))\n",
    "print(\"í”¼ì²˜ ì˜ˆì‹œ 20ê°œ:\", orig_feature_cols[:20])\n",
    "print(\"í”¼ì²˜ 110ê°œ:\", orig_feature_cols[:110])\n",
    "\n",
    "# X, y ìƒì„±\n",
    "X = train_df[orig_feature_cols].copy()\n",
    "y = train_df[TARGET_COL].copy()\n",
    "\n",
    "print(\"\\nX shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41118550",
   "metadata": {},
   "source": [
    "##### LGBM ìš© Safe ì»¬ëŸ¼ëª… ìƒì„± + ë¬¸ìì—´ Factorize\n",
    "- í•œê¸€/íŠ¹ìˆ˜ë¬¸ì ì»¬ëŸ¼ëª…ì„ ëª¨ë¸ì´ í•™ìŠµí•˜ê¸° ì¢‹ì€ í™˜ê²½ì¸ ì•ŒíŒŒë²³/ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€ê²½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d64c7e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe ì»¬ëŸ¼ ê°œìˆ˜: 125\n",
      "safe ìœ ë‹ˆí¬ ê°œìˆ˜: 125\n",
      "ì¤‘ë³µ safe ì´ë¦„ ê°œìˆ˜: 0\n",
      "\n",
      "[ì›ë˜ ì´ë¦„ â†’ safe ì´ë¦„ ë§¤í•‘ ì˜ˆì‹œ 10ê°œ]\n",
      "ì‹œêµ°êµ¬  -->  ___\n",
      "ë²ˆì§€  -->  __\n",
      "ë³¸ë²ˆ  -->  ____1\n",
      "ë¶€ë²ˆ  -->  ____2\n",
      "ì•„íŒŒíŠ¸ëª…  -->  ____\n",
      "ì „ìš©ë©´ì   -->  ______1\n",
      "ê³„ì•½ë…„ì›”  -->  ______2\n",
      "ê³„ì•½ì¼  -->  _____1\n",
      "ì¸µ  -->  _\n",
      "ê±´ì¶•ë…„ë„  -->  ______3\n"
     ]
    }
   ],
   "source": [
    "def make_base_safe_name(name: str) -> str:\n",
    "    # 1) í•œê¸€/íŠ¹ìˆ˜ë¬¸ì â†’ _ ë¡œ ì¹˜í™˜\n",
    "    safe = re.sub(r\"[^0-9a-zA-Z_]\", \"_\", name)\n",
    "    # 2) ì²« ê¸€ìê°€ ìˆ«ìë©´ ì ‘ë‘ì–´ ë¶™ì´ê¸°\n",
    "    if re.match(r\"^[0-9]\", safe):\n",
    "        safe = \"f_\" + safe\n",
    "    return safe\n",
    "\n",
    "safe_name_counts = {}\n",
    "safe_feature_cols = []\n",
    "\n",
    "for col in orig_feature_cols:\n",
    "    base = make_base_safe_name(col)\n",
    "    if base in safe_name_counts:\n",
    "        safe_name_counts[base] += 1\n",
    "        safe = f\"{base}__{safe_name_counts[base]}\"\n",
    "    else:\n",
    "        safe_name_counts[base] = 0\n",
    "        safe = base\n",
    "    safe_feature_cols.append(safe)\n",
    "\n",
    "# ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
    "orig2safe = dict(zip(orig_feature_cols, safe_feature_cols))\n",
    "safe2orig = dict(zip(safe_feature_cols, orig_feature_cols))\n",
    "\n",
    "# Xë¥¼ safe ì´ë¦„ìœ¼ë¡œ ë³€ê²½\n",
    "X_safe = X.rename(columns=orig2safe)\n",
    "\n",
    "print(\"safe ì»¬ëŸ¼ ê°œìˆ˜:\", len(safe_feature_cols))\n",
    "print(\"safe ìœ ë‹ˆí¬ ê°œìˆ˜:\", len(set(safe_feature_cols)))\n",
    "\n",
    "dups = [n for n in safe_feature_cols if safe_feature_cols.count(n) > 1]\n",
    "print(\"ì¤‘ë³µ safe ì´ë¦„ ê°œìˆ˜:\", len(set(dups)))\n",
    "\n",
    "print(\"\\n[ì›ë˜ ì´ë¦„ â†’ safe ì´ë¦„ ë§¤í•‘ ì˜ˆì‹œ 10ê°œ]\")\n",
    "for o, s in list(orig2safe.items())[:10]:\n",
    "    print(f\"{o}  -->  {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eee5d0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë²”ì£¼í˜•(ë¬¸ìì—´) ì»¬ëŸ¼ ìˆ˜: 34\n",
      "ë²”ì£¼í˜•(ë¬¸ìì—´) ì˜ˆì‹œ: ['___', '__', '____1', '____2', '____', '_____2', '______', '______4', '________1', 'k_________________']\n",
      "\n",
      "ì¸ì½”ë”© í›„ dtype ë¶„í¬:\n",
      "int64       66\n",
      "float64     57\n",
      "category     1\n",
      "category     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ìì—´(ë²”ì£¼í˜•) ì»¬ëŸ¼ safe ì´ë¦„ ê¸°ì¤€ìœ¼ë¡œ ì°¾ê¸°\n",
    "cat_cols_safe = [\n",
    "    orig2safe[c]\n",
    "    for c in orig_feature_cols\n",
    "    if X[c].dtype == \"object\"\n",
    "]\n",
    "\n",
    "print(\"ë²”ì£¼í˜•(ë¬¸ìì—´) ì»¬ëŸ¼ ìˆ˜:\", len(cat_cols_safe))\n",
    "print(\"ë²”ì£¼í˜•(ë¬¸ìì—´) ì˜ˆì‹œ:\", cat_cols_safe[:10])\n",
    "\n",
    "# factorize ì¸ì½”ë”©\n",
    "for c in cat_cols_safe:\n",
    "    X_safe[c], _ = pd.factorize(X_safe[c], sort=True)\n",
    "\n",
    "print(\"\\nì¸ì½”ë”© í›„ dtype ë¶„í¬:\")\n",
    "print(X_safe.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c1559a",
   "metadata": {},
   "source": [
    "##### Train / Valid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec6d79d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (895057, 125)\n",
      "X_valid shape: (223765, 125)\n",
      "y_train shape: (895057,)\n",
      "y_valid shape: (223765,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_safe,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_valid shape:\", y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c6ee1",
   "metadata": {},
   "source": [
    "##### LightGBM í•™ìŠµ ë° RMSE ì¸¡ì • ë° ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97198a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 1. Optuna objective í•¨ìˆ˜ ì •ì˜ (íŠœë‹ìš©)\\n#    - num_boost_round: 1000 (íŠœë‹ìš©ìœ¼ë¡œë§Œ ì¤„ì„)\\n#    - PruningCallback ì¶”ê°€ â†’ ì„±ëŠ¥ ì•ˆ ì¢‹ì€ trialì€ ì¤‘ê°„ì— ì»·\\n\\ndef objective(trial):\\n    params = {\\n        \"objective\": \"regression\",\\n        \"metric\": \"rmse\",\\n        \"boosting_type\": \"gbdt\",\\n        \"verbosity\": -1,\\n        \"random_state\": 42,\\n        \"num_threads\": -1,\\n\\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 255),\\n        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 16),\\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 300),\\n        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\\n        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\\n        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 10),\\n        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 5.0),\\n        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 5.0),\\n    }\\n\\n    train_data = lgb.Dataset(X_train, label=y_train)\\n    valid_data = lgb.Dataset(X_valid, label=y_valid)\\n\\n    # ğŸ”¹ ì—¬ê¸°ì„œ valid ì„¸íŠ¸ ì´ë¦„ì„ \"valid\"ë¡œ ëª…ì‹œ!\\n    pruning_callback = LightGBMPruningCallback(trial, \"rmse\", \"valid\")\\n\\n    model = lgb.train(\\n        params,\\n        train_data,\\n        num_boost_round=1000,\\n        valid_sets=[valid_data],\\n        valid_names=[\"valid\"],   # â† ì—¬ê¸°ì— ë§ì¶° \"valid\"ë¼ê³  ì§€ì •í–ˆìœ¼ë‹ˆê¹Œ\\n        callbacks=[\\n            lgb.early_stopping(stopping_rounds=100),\\n            lgb.log_evaluation(100),\\n            pruning_callback,\\n        ],\\n    )\\n\\n    y_valid_pred = model.predict(X_valid, num_iteration=model.best_iteration)\\n\\n    mse = mean_squared_error(y_valid, y_valid_pred)\\n    rmse = np.sqrt(mse)\\n    return rmse\\n\\n# 2. Optuna Study ì‹¤í–‰\\nprint(\"\\n[Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘]\")\\nstudy = optuna.create_study(\\n    direction=\"minimize\",\\n    sampler=optuna.samplers.TPESampler(seed=42),\\n)\\nstudy.optimize(objective, n_trials=30)   # ğŸ’¡ ìš°ì„  20~30 trialë¡œ ê°€ë³ê²Œ\\n\\nprint(\"\\n[Optuna ê²°ê³¼]\")\\nprint(\"Best RMSE:\", study.best_value)\\nprint(\"Best params:\", study.best_params)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Optuna objective í•¨ìˆ˜ ì •ì˜ (íŠœë‹ìš©)\n",
    "#    - num_boost_round: 1000 (íŠœë‹ìš©ìœ¼ë¡œë§Œ ì¤„ì„)\n",
    "#    - PruningCallback ì¶”ê°€ â†’ ì„±ëŠ¥ ì•ˆ ì¢‹ì€ trialì€ ì¤‘ê°„ì— ì»·\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"random_state\": 42,\n",
    "        \"num_threads\": -1,\n",
    "\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 255),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", -1, 16),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 300),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.6, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.6, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 0, 10),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 0.0, 5.0),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 0.0, 5.0),\n",
    "    }\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "    # ğŸ”¹ ì—¬ê¸°ì„œ valid ì„¸íŠ¸ ì´ë¦„ì„ \"valid\"ë¡œ ëª…ì‹œ!\n",
    "    pruning_callback = LightGBMPruningCallback(trial, \"rmse\", \"valid\")\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[valid_data],\n",
    "        valid_names=[\"valid\"],   # â† ì—¬ê¸°ì— ë§ì¶° \"valid\"ë¼ê³  ì§€ì •í–ˆìœ¼ë‹ˆê¹Œ\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=100),\n",
    "            lgb.log_evaluation(100),\n",
    "            pruning_callback,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    y_valid_pred = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "    mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# 2. Optuna Study ì‹¤í–‰\n",
    "print(\"\\n[Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘]\")\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    ")\n",
    "study.optimize(objective, n_trials=30)   # ğŸ’¡ ìš°ì„  20~30 trialë¡œ ê°€ë³ê²Œ\n",
    "\n",
    "print(\"\\n[Optuna ê²°ê³¼]\")\n",
    "print(\"Best RMSE:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "966abecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'learning_rate': 0.030710573677773714,\n",
    "    'num_leaves': 244,\n",
    "    'max_depth': 12,\n",
    "    'min_data_in_leaf': 188,\n",
    "    'feature_fraction': 0.6624074561769746,\n",
    "    'bagging_fraction': 0.662397808134481,\n",
    "    'bagging_freq': 0,\n",
    "    'lambda_l1': 4.330880728874676,\n",
    "    'lambda_l2': 3.005575058716044\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3517f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ìµœì¢… ëª¨ë¸ í•™ìŠµ ì‹œì‘]\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\tvalid's rmse: 16447.4\n",
      "[100]\tvalid's rmse: 10647.2\n",
      "[150]\tvalid's rmse: 9068.67\n",
      "[200]\tvalid's rmse: 8438.89\n",
      "[250]\tvalid's rmse: 8098.37\n",
      "[300]\tvalid's rmse: 7833.43\n",
      "[350]\tvalid's rmse: 7630.18\n",
      "[400]\tvalid's rmse: 7474.93\n",
      "[450]\tvalid's rmse: 7326.72\n",
      "[500]\tvalid's rmse: 7201.86\n",
      "[550]\tvalid's rmse: 7088.27\n",
      "[600]\tvalid's rmse: 6997.85\n",
      "[650]\tvalid's rmse: 6923.66\n",
      "[700]\tvalid's rmse: 6840.09\n",
      "[750]\tvalid's rmse: 6771.72\n",
      "[800]\tvalid's rmse: 6705\n",
      "[850]\tvalid's rmse: 6650.32\n",
      "[900]\tvalid's rmse: 6604.61\n",
      "[950]\tvalid's rmse: 6555.24\n",
      "[1000]\tvalid's rmse: 6496.34\n",
      "[1050]\tvalid's rmse: 6458.81\n",
      "[1100]\tvalid's rmse: 6418.18\n",
      "[1150]\tvalid's rmse: 6383.3\n",
      "[1200]\tvalid's rmse: 6347.81\n",
      "[1250]\tvalid's rmse: 6311.6\n",
      "[1300]\tvalid's rmse: 6281.26\n",
      "[1350]\tvalid's rmse: 6247.77\n",
      "[1400]\tvalid's rmse: 6220.75\n",
      "[1450]\tvalid's rmse: 6194.04\n",
      "[1500]\tvalid's rmse: 6174.76\n",
      "[1550]\tvalid's rmse: 6156.67\n",
      "[1600]\tvalid's rmse: 6141.23\n",
      "[1650]\tvalid's rmse: 6121.85\n",
      "[1700]\tvalid's rmse: 6101.84\n",
      "[1750]\tvalid's rmse: 6079.85\n",
      "[1800]\tvalid's rmse: 6060.23\n",
      "[1850]\tvalid's rmse: 6042.28\n",
      "[1900]\tvalid's rmse: 6026.08\n",
      "[1950]\tvalid's rmse: 6012.21\n",
      "[2000]\tvalid's rmse: 5999.32\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid's rmse: 5999.32\n",
      "[ìµœì¢… ëª¨ë¸ RMSE]: 5999.3202\n",
      "Best iteration: 2000\n"
     ]
    }
   ],
   "source": [
    "final_params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": 42,\n",
    "    \"num_threads\": -1,\n",
    "}\n",
    "final_params.update(best_params)\n",
    "\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "print(\"\\n[ìµœì¢… ëª¨ë¸ í•™ìŠµ ì‹œì‘]\")\n",
    "final_model = lgb.train(\n",
    "    final_params,\n",
    "    train_data,\n",
    "    num_boost_round=2000,               \n",
    "    valid_sets=[valid_data],\n",
    "    valid_names=[\"valid\"],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=100),\n",
    "        lgb.log_evaluation(50),\n",
    "    ],\n",
    ")\n",
    "\n",
    "y_pred = final_model.predict(X_valid, num_iteration=final_model.best_iteration)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print(f\"[ìµœì¢… ëª¨ë¸ RMSE]: {rmse:.4f}\")\n",
    "print(\"Best iteration:\", final_model.best_iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee444341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš°ë¦¬ê°€ ë§Œë“  ëŒ€í‘œ ì…ì§€ íŒŒìƒë³€ìˆ˜ë“¤ì„ ì¤‘ì‹¬ìœ¼ë¡œ í•œê¸€ ì´ë¦„ ë§¤í•‘\n",
    "rename_dict = {\n",
    "    # ì…ì§€ / ê°€ê²© í†µê³„\n",
    "    \"ë™_í‰ê· ê°€ê²©\": \"ë™ë³„ í‰ê·  ì‹¤ê±°ë˜ê°€\",\n",
    "    \"ë™_ê±°ë˜ëŸ‰\": \"ë™ë³„ ê±°ë˜ëŸ‰\",\n",
    "    \"êµ¬_í‰ê· ê°€ê²©\": \"êµ¬ë³„ í‰ê·  ì‹¤ê±°ë˜ê°€\",\n",
    "    \"êµ¬_ì¤‘ìœ„ê°€ê²©\": \"êµ¬ë³„ ì¤‘ìœ„ ì‹¤ê±°ë˜ê°€\",\n",
    "    \"êµ¬_ê±°ë˜ëŸ‰\": \"êµ¬ë³„ ê±°ë˜ëŸ‰\",\n",
    "\n",
    "    # ê°•ë‚¨ / ì—…ë¬´ì§€êµ¬\n",
    "    \"ê°•ë‚¨ì—¬ë¶€\": \"ê°•ë‚¨ 4êµ¬ ì—¬ë¶€\",\n",
    "    \"CBD_ì—¬ë¶€\": \"ë„ì‹¬(CBD) ì—¬ë¶€\",\n",
    "    \"GBD_ì—¬ë¶€\": \"ê°•ë‚¨ê¶Œ(GBD) ì—¬ë¶€\",\n",
    "    \"YBD_ì—¬ë¶€\": \"ì—¬ì˜ë„(YBD) ì—¬ë¶€\",\n",
    "\n",
    "    # ì§€í•˜ì² \n",
    "    \"subway_min_dist_km\": \"ê°€ì¥ ê°€ê¹Œìš´ ì§€í•˜ì² ì—­ ê±°ë¦¬(km)\",\n",
    "    \"subway_cnt_500m\": \"500m ë‚´ ì§€í•˜ì² ì—­ ìˆ˜\",\n",
    "    \"subway_cnt_1km\": \"1km ë‚´ ì§€í•˜ì² ì—­ ìˆ˜\",\n",
    "    \"subway_is_500m\": \"ì§€í•˜ì²  500m ì´ë‚´ ì—¬ë¶€\",\n",
    "\n",
    "    # ë²„ìŠ¤\n",
    "    \"bus_min_dist_km\": \"ê°€ì¥ ê°€ê¹Œìš´ ë²„ìŠ¤ì •ë¥˜ì¥ ê±°ë¦¬(km)\",\n",
    "    \"bus_cnt_300m\": \"300m ë‚´ ë²„ìŠ¤ì •ë¥˜ì¥ ìˆ˜\",\n",
    "    \"bus_cnt_500m\": \"500m ë‚´ ë²„ìŠ¤ì •ë¥˜ì¥ ìˆ˜\",\n",
    "    \"bus_is_300m\": \"ë²„ìŠ¤ 300m ì´ë‚´ ì—¬ë¶€\",\n",
    "    \"bus_is_500m\": \"ë²„ìŠ¤ 500m ì´ë‚´ ì—¬ë¶€\",\n",
    "\n",
    "    # í•™êµ ê±°ë¦¬\n",
    "    \"elem_min_dist_km\": \"ê°€ì¥ ê°€ê¹Œìš´ ì´ˆë“±í•™êµ ê±°ë¦¬(km)\",\n",
    "    \"mid_min_dist_km\": \"ê°€ì¥ ê°€ê¹Œìš´ ì¤‘í•™êµ ê±°ë¦¬(km)\",\n",
    "    \"high_min_dist_km\": \"ê°€ì¥ ê°€ê¹Œìš´ ê³ ë“±í•™êµ ê±°ë¦¬(km)\",\n",
    "    \"school_min_dist_km\": \"ê°€ì¥ ê°€ê¹Œìš´ í•™êµ ê±°ë¦¬(km)\",\n",
    "\n",
    "    # êµ¬ë³„ í•™êµ ìˆ˜\n",
    "    \"elem_school_cnt\": \"êµ¬ë³„ ì´ˆë“±í•™êµ ìˆ˜\",\n",
    "    \"mid_school_cnt\": \"êµ¬ë³„ ì¤‘í•™êµ ìˆ˜\",\n",
    "    \"high_school_cnt\": \"êµ¬ë³„ ê³ ë“±í•™êµ ìˆ˜\",\n",
    "\n",
    "    # ê±´ì¶•ë…„ë„ ë° ì—°ì‹ ê´€ë ¨\n",
    "    \"building_age\": \"ê±´ë¬¼ë‚˜ì´\",\n",
    "    \"building_age_bucket\": \"ë…¸í›„ë„êµ¬ê°„\",\n",
    "    \"year_group\": \"ê±´ì¶•ë…„ë„_êµ¬ê°„\",\n",
    "    \"year_sq\": \"ê±´ì¶•ë…„ë„_ì œê³±\",\n",
    "    \"year_sqrt\": \"ê±´ì¶•ë…„ë„_ë£¨íŠ¸\",\n",
    "\n",
    "    # ì¸µìˆ˜ ê´€ë ¨\n",
    "    \"floor_bucket\": \"ì¸µìˆ˜_êµ¬ê°„\",\n",
    "    \"floor_abs\": \"ì¸µ_ì ˆëŒ“ê°’\",\n",
    "    \"is_low_floor\": \"ì €ì¸µ\",\n",
    "    \"is_mid_floor\": \"ì¤‘ì¸µ\",\n",
    "    \"is_high_floor\": \"ê³ ì¸µ\",\n",
    "\n",
    "    # ë‹¨ì§€ ê¸°ë°˜\n",
    "    \"max_floor_in_complex\": \"ë‹¨ì§€_ìµœê³ ì¸µ\",\n",
    "    \"is_top_floor\": \"ìµœìƒì¸µ\",\n",
    "    \"complex_scale\": \"ë‹¨ì§€ê·œëª¨\",\n",
    "\n",
    "    # ì§€ì—­ ê¸°ë°˜\n",
    "    \"avg_age_by_dong\": \"ë™_í‰ê· ì—°ì‹\",\n",
    "    \"avg_floor_by_dong\": \"ë™_í‰ê· ì¸µìˆ˜\",\n",
    "    \"ratio_new_buildings\": \"ë™_ì‹ ì¶•ë¹„ìœ¨\",\n",
    "\n",
    "    # í‰ ê¸°ë°˜\n",
    "    \"log_area\": \"ì „ìš©ë©´ì _log\",\n",
    "    \"area_pyeong\": \"í‰ìˆ˜\",\n",
    "    \"area_bucket\": \"í‰ìˆ˜êµ¬ê°„\",\n",
    "    \"price_per_pyeong\": \"í‰ë‹¹ê°€ê²©\",\n",
    "    \"dong_avg_pyp\": \"ë™ë³„ í‰ê·  í‰ë‹¹ê°€ê²©\",\n",
    "\n",
    "    # ê±°ë˜ ì‹œì \n",
    "    \"contract_year\": \"ê³„ì•½ì—°ë„\",\n",
    "    \"contract_month\": \"ê³„ì•½ì›”\",\n",
    "    \"contract_quarter\": \"ê³„ì•½ë¶„ê¸°\",\n",
    "    \"season\": \"ê³„ì•½ê³„ì ˆ\",\n",
    "    \"yearly_price_growth\": \"êµ¬_ì—°ê°„ê°€ê²©ì¦ê°€ìœ¨\",\n",
    "\n",
    "    # ê±°ë˜ íŠ¹ì„±\n",
    "    \"same_apt_area_total_trades\": \"ë™ì¼ë‹¨ì§€ë©´ì _ì´ê±°ë˜ìˆ˜\",\n",
    "    \"same_apt_area_past_trades\": \"ë™ì¼ë‹¨ì§€ë©´ì _ê³¼ê±°ê±°ë˜ìˆ˜\",\n",
    "\n",
    "    # ì•„íŒŒíŠ¸ ì´ë¦„ ê¸°ë°˜ í…ìŠ¤íŠ¸\n",
    "    \"is_brand_apt\": \"ë¸Œëœë“œì•„íŒŒíŠ¸ì—¬ë¶€\",\n",
    "    \"has_redev_keyword\": \"ì¬ê±´ì¶•í‚¤ì›Œë“œì—¬ë¶€\",\n",
    "    \"has_scale_keyword\": \"ê·œëª¨í‚¤ì›Œë“œì—¬ë¶€\",\n",
    "\n",
    "    # ê¸ˆë¦¬\n",
    "    \"base_rate\": \"ê¸°ì¤€ê¸ˆë¦¬\",\n",
    "    \"base_mom\": \"ê¸°ì¤€ê¸ˆë¦¬_ì „ì›”ë³€í™”\",\n",
    "    \"base_yoy\": \"ê¸°ì¤€ê¸ˆë¦¬_ì „ë…„ë™ì›”ë³€í™”\",\n",
    "\n",
    "    \"mortgage_rate\": \"ì£¼ë‹´ëŒ€ê¸ˆë¦¬\",\n",
    "    \"mortgage_mom\": \"ì£¼ë‹´ëŒ€ê¸ˆë¦¬_ì „ì›”ë³€í™”\",\n",
    "    \"mortgage_yoy\": \"ì£¼ë‹´ëŒ€ê¸ˆë¦¬_ì „ë…„ë™ì›”ë³€í™”\",\n",
    "\n",
    "    \"spread\": \"ëŒ€ì¶œ-ê¸°ì¤€ê¸ˆë¦¬_ìŠ¤í”„ë ˆë“œ\",\n",
    "    \"spread_mom\": \"ìŠ¤í”„ë ˆë“œ_ì „ì›”ë³€í™”\",\n",
    "\n",
    "    \"mortgage_ma3\": \"ì£¼ë‹´ëŒ€ê¸ˆë¦¬_3ê°œì›”ì´ë™í‰ê· \",\n",
    "    \"mortgage_ma6\": \"ì£¼ë‹´ëŒ€ê¸ˆë¦¬_6ê°œì›”ì´ë™í‰ê· \",\n",
    "\n",
    "    \"mortgage_lag1\": \"ì£¼ë‹´ëŒ€ê¸ˆë¦¬_L1\",\n",
    "    \"mortgage_lag3\": \"ì£¼ë‹´ëŒ€ê¸ˆë¦¬_L3\",\n",
    "    \"mortgage_lag6\": \"ì£¼ë‹´ëŒ€ê¸ˆë¦¬_L6\",\n",
    "\n",
    "    \"base_rate_bucket\": \"ê¸°ì¤€ê¸ˆë¦¬_êµ¬ê°„\",\n",
    "    \"mortgage_rate_bucket\": \"ì£¼ë‹´ëŒ€ê¸ˆë¦¬_êµ¬ê°„\",\n",
    "\n",
    "    # ê¸°íƒ€ (ê¸°ì¡´ ë³€ìˆ˜ë“¤ë„ í•„ìš”í•˜ë©´ ì—¬ê¸° ì¶”ê°€)\n",
    "    \"ì „ìš©ë©´ì \": \"ì „ìš©ë©´ì (ã¡)\",\n",
    "    \"ê³„ì•½ë…„ì›”\": \"ê³„ì•½ì—°ì›”\",\n",
    "    \"ê³„ì•½ì¼\": \"ê³„ì•½ì¼\",\n",
    "    \"ê±´ì¶•ë…„ë„\": \"ê±´ì¶•ë…„ë„\",\n",
    "    \"ì¸µ\": \"í•´ë‹¹ ì¸µìˆ˜\",\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e05a4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Feature Importance ìƒìœ„ 20ê°œ]\n",
      "                       feature feature_readable  importance_gain\n",
      "0                       ë™_í‰ê· ê°€ê²©       ë™ë³„ í‰ê·  ì‹¤ê±°ë˜ê°€     7.456475e+15\n",
      "1                         ì „ìš©ë©´ì           ì „ìš©ë©´ì (ã¡)     4.693366e+15\n",
      "2                         ê³„ì•½ë…„ì›”             ê³„ì•½ì—°ì›”     4.042798e+15\n",
      "3                 dong_avg_pyp       ë™ë³„ í‰ê·  í‰ë‹¹ê°€ê²©     3.803675e+15\n",
      "4                     log_area         ì „ìš©ë©´ì _log     2.357958e+15\n",
      "5                contract_year             ê³„ì•½ì—°ë„     1.200348e+15\n",
      "6                       êµ¬_í‰ê· ê°€ê²©       êµ¬ë³„ í‰ê·  ì‹¤ê±°ë˜ê°€     9.840436e+14\n",
      "7                  area_pyeong               í‰ìˆ˜     9.637072e+14\n",
      "8                         ê±´ì¶•ë…„ë„             ê±´ì¶•ë…„ë„     7.647605e+14\n",
      "9         max_floor_in_complex           ë‹¨ì§€_ìµœê³ ì¸µ     4.883796e+14\n",
      "10                mortgage_ma6    ì£¼ë‹´ëŒ€ê¸ˆë¦¬_6ê°œì›”ì´ë™í‰ê·      2.704190e+14\n",
      "11  same_apt_area_total_trades      ë™ì¼ë‹¨ì§€ë©´ì _ì´ê±°ë˜ìˆ˜     2.580426e+14\n",
      "12                building_age             ê±´ë¬¼ë‚˜ì´     2.545086e+14\n",
      "13                   base_rate             ê¸°ì¤€ê¸ˆë¦¬     2.270820e+14\n",
      "14                      êµ¬_ì¤‘ìœ„ê°€ê²©       êµ¬ë³„ ì¤‘ìœ„ ì‹¤ê±°ë˜ê°€     1.897903e+14\n",
      "15                        ê±°ë˜ìœ í˜•             ê±°ë˜ìœ í˜•     1.893766e+14\n",
      "16               mortgage_rate            ì£¼ë‹´ëŒ€ê¸ˆë¦¬     1.761993e+14\n",
      "17                         ë„ë¡œëª…              ë„ë¡œëª…     1.730277e+14\n",
      "18                      spread     ëŒ€ì¶œ-ê¸°ì¤€ê¸ˆë¦¬_ìŠ¤í”„ë ˆë“œ     1.706986e+14\n",
      "19             avg_age_by_dong           ë™_í‰ê· ì—°ì‹     1.583308e+14\n"
     ]
    }
   ],
   "source": [
    "# 1. final_modelì—ì„œ feature importance ì¶”ì¶œ (safe ì´ë¦„ ê¸°ì¤€)\n",
    "importance_gain = final_model.feature_importance(importance_type=\"gain\")\n",
    "importance_split = final_model.feature_importance(importance_type=\"split\")\n",
    "feature_safe = final_model.feature_name()   # â† safe ì´ë¦„ë“¤\n",
    "\n",
    "# 2. DataFrame ìƒì„± (safe ì´ë¦„ ê¸°ì¤€)\n",
    "fi_df = pd.DataFrame({\n",
    "    \"feature_safe\": feature_safe,\n",
    "    \"importance_gain\": importance_gain,\n",
    "    \"importance_split\": importance_split,\n",
    "})\n",
    "\n",
    "# 3. safe â†’ ì›ë˜ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë§¤í•‘ (ìœ„ì—ì„œ ë§Œë“  safe2orig ì‚¬ìš©)\n",
    "fi_df[\"feature\"] = fi_df[\"feature_safe\"].map(safe2orig)\n",
    "\n",
    "# 4. ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "fi_df = fi_df.sort_values(\"importance_gain\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 5. ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ í•œê¸€ ë¼ë²¨ (rename_dict ì‚¬ìš©)\n",
    "fi_df[\"feature_readable\"] = fi_df[\"feature\"].map(rename_dict)\n",
    "fi_df[\"feature_readable\"] = fi_df[\"feature_readable\"].fillna(fi_df[\"feature\"])\n",
    "\n",
    "print(\"\\n[Feature Importance ìƒìœ„ 20ê°œ]\")\n",
    "print(fi_df[[\"feature\", \"feature_readable\", \"importance_gain\"]].head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Feature Importance ì €ì¥ ì™„ë£Œ: ./Data/03_model_end/feature_importance_gain.csv\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"./Data/03_model_end\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "FI_PATH = os.path.join(OUTPUT_DIR, \"feature_importance_gain.csv\")\n",
    "fi_df.to_csv(FI_PATH, index=False, encoding=\"utf-8-sig\")\n",
    "print(\"Feature Importance ì €ì¥ ì™„ë£Œ:\", FI_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d73f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Top60 feature ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: ./Data/03_model_end/top60_features.json\n"
     ]
    }
   ],
   "source": [
    "TOP_N = 60\n",
    "top_features = fi_df[\"feature\"].head(TOP_N).tolist()\n",
    "\n",
    "TOP_FEATURES_PATH = os.path.join(OUTPUT_DIR, f\"top{TOP_N}_features.json\")\n",
    "with open(TOP_FEATURES_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(top_features, f, ensure_ascii=False)\n",
    "\n",
    "print(f\"Top{TOP_N} feature ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ:\", TOP_FEATURES_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
